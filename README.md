# Описание проекта: LLM-Spring-Client

## 1. Краткое описание (Executive Summary):

Проект представляет собой серверное веб-приложение — интеллектуальный чат-бот, реализованный на Java с использованием фреймворка Spring Boot и модуля Spring AI. Бот предназначен для ведения текстового диалога с пользователями, отвечая на их вопросы в естественной форме, подобно современным AI-ассистентам (наподобие ChatGPT). Ядром приложения является мощная языковая модель (LLM), доступ к которой абстрагирован средствами Spring AI, что обеспечивает простоту интеграции и возможность легкой смены провайдера AI (OpenAI, Azure OpenAI, Ollama и др.).

## 2. Цели и Задачи:

Цель: Создать масштабируемое, легко интегрируемое и поддерживаемое API для AI-чата.

Задачи:

 - Предоставить RESTful API endpoint для отправки сообщений и получения ответов от ИИ.

 - Интегрироваться с одним или несколькими провайдерами Language Model (LLM).

- Реализовать базовый механизм истории диалога (памяти) для поддержания контекста беседы в рамках сессии.

- Обеспечить обработку ошибок и стандартизированные ответы API.

- Создать основу для будущего расширения функционала (например, мультимодальность, инструменты (tools), изоляция пользовательских сессий).

## 3. Технологический Стек:

Язык: Java 21 или выше (LTS)

Фреймворк: Spring Boot 3.2+

AI Framework: Spring AI (версия 1.0.0+)

LLM Провайдер: OpenAI GPT-4 или GPT-3.5-Turbo (по умолчанию), с возможностью подключения других (Anthropic, Ollama/Local LM, Azure OpenAI)

Билд-менеджер: Maven

Дополнительно: Spring Web, Thymeleaf, Postgres vector, Lombok

## 4. Архитектура и Ключевые Компоненты:

### Контроллеры (ChatController):

REST-контроллеры, обрабатывающий HTTP-запросы (StreamingChatController).

Принимает сообщение в параметрах запроса пользователя и возвращается ответ в качестве потока данных (Stream).


### Сервисы (ChatService, DocumentLoaderService):

ChatService - cодержит основную бизнес-логику взаимодействия с AI.

Использует Spring AI клиент (ChatClient) или более продвинутый AiService для общения с LLM.

Отвечает за формирование промпта (запроса к модели) и обработку ответа.

DocumentLoaderService - содержит логику обработки для загрузки документов для RAG (Retrieval-Augmented Generation) — чтобы бот отвечал на основе ваших собственных документов.


### Конфигурация (LLMConfig, PostgresChatMemory, application.yml, docker-compose.yml):

LLMConfig - класс для конфигурации адвайзеров и для подключения RAG.

PostgresChatMemory - класс для конфигурации историй сообщений, которые подсказывает модели в каком контексте ведется диалог.

Конфигурационные параметры подключения к базе данных и LLM провайдеру вынесены в application.yml.

docker-compoce.yml - позволит развернуть окружение для работы приложения (ankane/pgvector, ollama)


## 5. Запуск и Развертывание:

Клонировать репозиторий.

Выполнить установку и настройку окружения с помощью файла docker-compose.yml

Собрать проект: mvn clean install -DskipTests.

Запустить приложение: java -jar target/LLM-Spring-Client-0.0.1-SNAPSHOT.jar

Приложение будет доступно на http://localhost:8080.

## 6. Направления для будущего развития:

Добавление аутентификации и изоляции диалогов по пользователям.

Добавление панели администратора для мониторинга запросов и управления промптами.

Интеграция с другими провайдерами моделей (Anthropic Claude, локальные модели через Ollama).

Добавление механизма "инструментов" (tools), позволяющего ИИ выполнять действия (например, искать погоду, делать бронирование).
