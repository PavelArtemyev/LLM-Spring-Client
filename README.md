Описание проекта: Spring AI ChatBot

1. Краткое описание (Executive Summary):

Проект представляет собой серверное веб-приложение — интеллектуальный чат-бот, реализованный на Java с использованием фреймворка Spring Boot и модуля Spring AI. Бот предназначен для ведения текстового диалога с пользователями, отвечая на их вопросы в естественной форме, подобно современным AI-ассистентам (наподобие ChatGPT). Ядром приложения является мощная языковая модель (LLM), доступ к которой абстрагирован средствами Spring AI, что обеспечивает простоту интеграции и возможность легкой смены провайдера AI (OpenAI, Azure OpenAI, Ollama и др.).

2. Цели и Задачи:

Цель: Создать масштабируемое, легко интегрируемое и поддерживаемое API для AI-чата.

Задачи:

Предоставить RESTful API endpoint для отправки сообщений и получения ответов от ИИ.

Интегрироваться с одним или несколькими провайдерами Language Model (LLM).

Реализовать базовый механизм истории диалога (памяти) для поддержания контекста беседы в рамках сессии.

Обеспечить обработку ошибок и стандартизированные ответы API.

Создать основу для будущего расширения функционала (например, мультимодальность, инструменты (tools), изоляция пользовательских сессий).

3. Технологический Стек:

Язык: Java 21 или выше (LTS)

Фреймворк: Spring Boot 3.2+

AI Framework: Spring AI (версия 1.0.0+)

LLM Провайдер: OpenAI GPT-4 или GPT-3.5-Turbo (по умолчанию), с возможностью подключения других (Anthropic, Ollama/Local LM, Azure OpenAI)

Билд-менеджер: Maven

Дополнительно: Spring Web, Thymeleaf, Postgres vector, Lombok

4. Архитектура и Ключевые Компоненты:

Контроллеры (ChatController, StreamingChatController):

REST-контроллеры, обрабатывающий HTTP-запросы.

Содержит endpoint POST /chat.

Принимает сообщение в параметрах запроса пользователя и возваращается ответ в в качестве потока данных (Stream).


Сервисы (ChatService, DocumentLoaderService):

ChatService - cодержит основную бизнес-логику взаимодействия с AI.

Использует Spring AI клиент (ChatClient) или более продвинутый AiService для общения с LLM.

Отвечает за формирование промпта (запроса к модели) и обработку ответа.

DocumentLoaderService - содержит логику обработки для загрузки документов для RAG (Retrieval-Augmented Generation) — чтобы бот отвечал на основе ваших собственных документов.


Конфигурация (LLMConfig, PostgresChatMemory, application.yml, docker-compose.yml):

LLMConfig - класс для конфигурации адвайзеров и для подключения RAG.

PostgresChatMemory - класс для конфигурации историй сообщений, которые подсказывает модели в каком контексте ведется диалог.

Конфигурационные параметры подключения к базе данных и LLM провайдеру вынесены в application.yml.

docker-compoce.yml - позволит развернуть окружение для работы приложения (ankane/pgvector, ollama)


5. Запуск и Развертывание:

Клонировать репозиторий.

Установить переменную окружения OPENAI_API_KEY со своим ключом от OpenAI.

Собрать проект: mvn clean install.

Запустить приложение: java -jar target/ai-chatbot.jar.

Приложение будет доступно на http://localhost:8080.

6. Направления для будущего развития:

Добавление аутентификации и изоляции диалогов по пользователям.

Подключение векторной базы данных (Vector Database) для RAG (Retrieval-Augmented Generation) — чтобы бот отвечал на основе ваших собственных документов.

Реализация потоковой передачи ответов (Streaming) для быстрого получения ответа по частям.

Добавление панели администратора для мониторинга запросов и управления промптами.

Интеграция с другими провайдерами моделей (Anthropic Claude, локальные модели через Ollama).

Добавление механизма "инструментов" (tools), позволяющего ИИ выполнять действия (например, искать погоду, делать бронирование).
